{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa8eab1-07bb-4f6d-841e-38f8d7bae97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0464b3bb-50cf-423c-aaf6-3648a4ba61e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9003dbba-cec1-4d26-a0f4-b3cf2154a90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/10 17:22:29 WARN Utils: Your hostname, Nishants-MacBook-Air.local resolves to a loopback address: 127.0.2.3; using 192.168.1.2 instead (on interface en0)\n",
      "24/08/10 17:22:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/10 17:22:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 61202)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socketserver.py\", line 318, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socketserver.py\", line 349, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socketserver.py\", line 362, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socketserver.py\", line 761, in __init__\n",
      "    self.handle()\n",
      "  File \"/Users/nishantketu/Projects/python-playground/venv/lib/python3.12/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/Users/nishantketu/Projects/python-playground/venv/lib/python3.12/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/Users/nishantketu/Projects/python-playground/venv/lib/python3.12/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nishantketu/Projects/python-playground/venv/lib/python3.12/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fbe08a8-4ef7-466e-9469-9d5dec23d984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "250a4ca1-6c4f-40e5-bd00-80e785763be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method createDataFrame in module pyspark.sql.session:\n",
      "\n",
      "createDataFrame(data: Union[pyspark.rdd.RDD[Any], Iterable[Any], ForwardRef('PandasDataFrameLike'), ForwardRef('ArrayLike')], schema: Union[pyspark.sql.types.AtomicType, pyspark.sql.types.StructType, str, NoneType] = None, samplingRatio: Optional[float] = None, verifySchema: bool = True) -> pyspark.sql.dataframe.DataFrame method of pyspark.sql.session.SparkSession instance\n",
      "    Creates a :class:`DataFrame` from an :class:`RDD`, a list, a :class:`pandas.DataFrame`\n",
      "    or a :class:`numpy.ndarray`.\n",
      "\n",
      "    .. versionadded:: 2.0.0\n",
      "\n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    data : :class:`RDD` or iterable\n",
      "        an RDD of any kind of SQL data representation (:class:`Row`,\n",
      "        :class:`tuple`, ``int``, ``boolean``, etc.), or :class:`list`,\n",
      "        :class:`pandas.DataFrame` or :class:`numpy.ndarray`.\n",
      "    schema : :class:`pyspark.sql.types.DataType`, str or list, optional\n",
      "        a :class:`pyspark.sql.types.DataType` or a datatype string or a list of\n",
      "        column names, default is None. The data type string format equals to\n",
      "        :class:`pyspark.sql.types.DataType.simpleString`, except that top level struct type can\n",
      "        omit the ``struct<>``.\n",
      "\n",
      "        When ``schema`` is a list of column names, the type of each column\n",
      "        will be inferred from ``data``.\n",
      "\n",
      "        When ``schema`` is ``None``, it will try to infer the schema (column names and types)\n",
      "        from ``data``, which should be an RDD of either :class:`Row`,\n",
      "        :class:`namedtuple`, or :class:`dict`.\n",
      "\n",
      "        When ``schema`` is :class:`pyspark.sql.types.DataType` or a datatype string, it must\n",
      "        match the real data, or an exception will be thrown at runtime. If the given schema is\n",
      "        not :class:`pyspark.sql.types.StructType`, it will be wrapped into a\n",
      "        :class:`pyspark.sql.types.StructType` as its only field, and the field name will be\n",
      "        \"value\". Each record will also be wrapped into a tuple, which can be converted to row\n",
      "        later.\n",
      "    samplingRatio : float, optional\n",
      "        the sample ratio of rows used for inferring. The first few rows will be used\n",
      "        if ``samplingRatio`` is ``None``.\n",
      "    verifySchema : bool, optional\n",
      "        verify data types of every row against schema. Enabled by default.\n",
      "\n",
      "        .. versionadded:: 2.1.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    :class:`DataFrame`\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Usage with `spark.sql.execution.arrow.pyspark.enabled=True` is experimental.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Create a DataFrame from a list of tuples.\n",
      "\n",
      "    >>> spark.createDataFrame([('Alice', 1)]).show()\n",
      "    +-----+---+\n",
      "    |   _1| _2|\n",
      "    +-----+---+\n",
      "    |Alice|  1|\n",
      "    +-----+---+\n",
      "\n",
      "    Create a DataFrame from a list of dictionaries.\n",
      "\n",
      "    >>> d = [{'name': 'Alice', 'age': 1}]\n",
      "    >>> spark.createDataFrame(d).show()\n",
      "    +---+-----+\n",
      "    |age| name|\n",
      "    +---+-----+\n",
      "    |  1|Alice|\n",
      "    +---+-----+\n",
      "\n",
      "    Create a DataFrame with column names specified.\n",
      "\n",
      "    >>> spark.createDataFrame([('Alice', 1)], ['name', 'age']).show()\n",
      "    +-----+---+\n",
      "    | name|age|\n",
      "    +-----+---+\n",
      "    |Alice|  1|\n",
      "    +-----+---+\n",
      "\n",
      "    Create a DataFrame with the explicit schema specified.\n",
      "\n",
      "    >>> from pyspark.sql.types import *\n",
      "    >>> schema = StructType([\n",
      "    ...    StructField(\"name\", StringType(), True),\n",
      "    ...    StructField(\"age\", IntegerType(), True)])\n",
      "    >>> spark.createDataFrame([('Alice', 1)], schema).show()\n",
      "    +-----+---+\n",
      "    | name|age|\n",
      "    +-----+---+\n",
      "    |Alice|  1|\n",
      "    +-----+---+\n",
      "\n",
      "    Create a DataFrame with the schema in DDL formatted string.\n",
      "\n",
      "    >>> spark.createDataFrame([('Alice', 1)], \"name: string, age: int\").show()\n",
      "    +-----+---+\n",
      "    | name|age|\n",
      "    +-----+---+\n",
      "    |Alice|  1|\n",
      "    +-----+---+\n",
      "\n",
      "    Create an empty DataFrame.\n",
      "    When initializing an empty DataFrame in PySpark, it's mandatory to specify its schema,\n",
      "    as the DataFrame lacks data from which the schema can be inferred.\n",
      "\n",
      "    >>> spark.createDataFrame([], \"name: string, age: int\").show()\n",
      "    +----+---+\n",
      "    |name|age|\n",
      "    +----+---+\n",
      "    +----+---+\n",
      "\n",
      "    Create a DataFrame from Row objects.\n",
      "\n",
      "    >>> from pyspark.sql import Row\n",
      "    >>> Person = Row('name', 'age')\n",
      "    >>> df = spark.createDataFrame([Person(\"Alice\", 1)])\n",
      "    >>> df.show()\n",
      "    +-----+---+\n",
      "    | name|age|\n",
      "    +-----+---+\n",
      "    |Alice|  1|\n",
      "    +-----+---+\n",
      "\n",
      "    Create a DataFrame from a pandas DataFrame.\n",
      "\n",
      "    >>> spark.createDataFrame(df.toPandas()).show()  # doctest: +SKIP\n",
      "    +-----+---+\n",
      "    | name|age|\n",
      "    +-----+---+\n",
      "    |Alice|  1|\n",
      "    +-----+---+\n",
      "    >>> spark.createDataFrame(pandas.DataFrame([[1, 2]])).collect()  # doctest: +SKIP\n",
      "    +---+---+\n",
      "    |  0|  1|\n",
      "    +---+---+\n",
      "    |  1|  2|\n",
      "    +---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(spark.createDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc3788c-bb4e-4bf0-954c-7d7ab3c08641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|   name|\n",
      "+---+-------+\n",
      "|  1|Nishant|\n",
      "|  2|   ketu|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[(1,\"Nishant\"),(2,\"ketu\")]\n",
    "df1=spark.createDataFrame(data=data,schema=['id','name'])\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b271b49-1b46-496a-b2f2-38641220a4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f762294-c603-40e7-bb19-6c3bfaa90134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "schema=StructType([StructField(name=\"id\",dataType=IntegerType()),\n",
    "            StructField(name=\"name\",dataType=StringType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d8665b4-52e9-4d5c-9097-92ec2ef7646a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.StructType"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db256cd4-31ef-485c-bfc3-1f225fa071f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|   name|\n",
      "+---+-------+\n",
      "|  1|Nishant|\n",
      "|  2|   ketu|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=spark.createDataFrame(data=data,schema=schema)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2a5bd07-2437-45a5-a7da-2a6de062660c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ff5d8a4-c4cb-4a7d-9e3f-4a3f167374d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|   name|\n",
      "+---+-------+\n",
      "|  1|nishant|\n",
      "|  2|   ketu|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[{\"id\":1,\"name\":\"nishant\"},\n",
    "      {\"id\":2,\"name\":\"ketu\"}\n",
    "     ]\n",
    "df3=spark.createDataFrame(data=data)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "679d669a-0ded-4bba-b189-b043f78cbe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b5e1f91-1a1e-4b84-ac18-4f66c0226415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Index: int, User Id: string, First Name: string, Last Name: string, Sex: string, Email: string, Phone: string, Date of birth: date, Job Title: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+--------------------+\n",
      "|Index|        User Id|First Name|Last Name|   Sex|               Email|               Phone|Date of birth|           Job Title|\n",
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+--------------------+\n",
      "|    1|88F7B33d2bcf9f5|    Shelby|  Terrell|  Male|elijah57@example.net|001-084-906-7849x...|   1945-10-26|     Games developer|\n",
      "|    2|f90cD3E76f1A9b9|   Phillip|  Summers|Female|bethany14@example...|   214.112.6044x4913|   1910-03-24|      Phytotherapist|\n",
      "|    3|DbeAb8CcdfeFC2c|  Kristine|   Travis|  Male|bthompson@example...|        277.609.7938|   1992-07-02|           Homeopath|\n",
      "|    4|A31Bee3c201ef58|   Yesenia| Martinez|  Male|kaitlinkaiser@exa...|        584.094.6111|   2017-08-03|   Market researcher|\n",
      "|    5|1bA7A3dc874da3c|      Lori|     Todd|  Male|buchananmanuel@ex...|   689-207-3558x7233|   1938-12-01|  Veterinary surgeon|\n",
      "|    6|bfDD7CDEF5D865B|      Erin|      Day|  Male| tconner@example.org|001-171-649-9856x...|   2015-10-28|Waste management ...|\n",
      "|    7|bE9EEf34cB72AF7| Katherine|     Buck|Female|conniecowan@examp...|+1-773-151-6685x4...|   1989-01-22|Intelligence analyst|\n",
      "|    8|2EFC6A4e77FaEaC|   Ricardo|   Hinton|  Male|wyattbishop@examp...|001-447-699-7998x...|   1924-03-26|      Hydrogeologist|\n",
      "|    9|baDcC4DeefD8dEB|      Dave|  Farrell|  Male| nmccann@example.net|  603-428-2429x27392|   2018-10-06|              Lawyer|\n",
      "|   10|8e4FB470FE19bF0|    Isaiah|    Downs|  Male|virginiaterrell@e...|+1-511-372-1544x8206|   1964-09-20|      Engineer, site|\n",
      "|   11|BF0BbA03C29Bb3b|    Sheila|     Ross|Female|huangcathy@exampl...|        895.881.4746|   2008-03-20|Advertising accou...|\n",
      "|   12|F738c69fB34E62E|     Stacy|   Newton|  Male|rayleroy@example.org|  710.673.3213x80335|   1980-10-20|       Warden/ranger|\n",
      "|   13|C03fDADdAadAdCe|     Mandy|    Blake|  Male|jefferynoble@exam...|  (992)466-1305x4947|   2007-12-08|Scientist, clinic...|\n",
      "|   14|b759b74BD1dE80d|   Bridget|     Nash|Female|mercedes44@exampl...|       (216)627-8359|   2004-06-28|       Social worker|\n",
      "|   15|1F0B7D65A00DAF9|   Crystal|   Farmer|  Male|pmiranda@example.org|     +1-024-377-5391|   1992-03-09|Agricultural cons...|\n",
      "|   16|50Bb061cB30B461|    Thomas|   Knight|Female|braunpriscilla@ex...|     +1-360-880-0766|   2006-02-18|Sport and exercis...|\n",
      "|   17|D6dbA5308fEC4BC|   Maurice|   Rangel|  Male|sheenabanks@examp...|       (246)187-4969|   2004-08-20|Secretary/adminis...|\n",
      "|   18|311D775990f066d|     Frank|  Meadows|  Male| gbrewer@example.org|   429.965.3902x4447|   2008-09-16|Audiological scie...|\n",
      "|   19|7F7E1BAcb0C9AFf|     Alvin|     Paul|  Male|gilbertdonaldson@...|  219.436.0887x07551|   1949-05-12|Teacher, adult ed...|\n",
      "|   20|88473e15D5c3cD0|     Jared| Mitchell|Female| jcortez@example.com|     +1-958-849-6781|   1921-01-18|    Paediatric nurse|\n",
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1=spark.read.csv(path='people-100.csv',header=True,inferSchema=True)\n",
    "# df1=spark.read.csv(path='people-100.csv',header=True)\n",
    "# without inferSchema everything is string\n",
    "# use array of path for adding multiple files\n",
    "display(df1)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b441a81e-cdb4-4a99-a219-ebf9e0f7b91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Index: integer (nullable = true)\n",
      " |-- User Id: string (nullable = true)\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Last Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Phone: string (nullable = true)\n",
      " |-- Date of birth: date (nullable = true)\n",
      " |-- Job Title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95884a07-cc1a-4a5c-bd63-8a3f75054b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Index: int, User Id: string, First Name: string, Last Name: string, Sex: string, Email: string, Phone: string, Date of birth: date, Job Title: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+--------------------+\n",
      "|Index|        User Id|First Name|Last Name|   Sex|               Email|               Phone|Date of birth|           Job Title|\n",
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+--------------------+\n",
      "|    1|88F7B33d2bcf9f5|    Shelby|  Terrell|  Male|elijah57@example.net|001-084-906-7849x...|   1945-10-26|     Games developer|\n",
      "|    2|f90cD3E76f1A9b9|   Phillip|  Summers|Female|bethany14@example...|   214.112.6044x4913|   1910-03-24|      Phytotherapist|\n",
      "|    3|DbeAb8CcdfeFC2c|  Kristine|   Travis|  Male|bthompson@example...|        277.609.7938|   1992-07-02|           Homeopath|\n",
      "|    4|A31Bee3c201ef58|   Yesenia| Martinez|  Male|kaitlinkaiser@exa...|        584.094.6111|   2017-08-03|   Market researcher|\n",
      "|    5|1bA7A3dc874da3c|      Lori|     Todd|  Male|buchananmanuel@ex...|   689-207-3558x7233|   1938-12-01|  Veterinary surgeon|\n",
      "|    6|bfDD7CDEF5D865B|      Erin|      Day|  Male| tconner@example.org|001-171-649-9856x...|   2015-10-28|Waste management ...|\n",
      "|    7|bE9EEf34cB72AF7| Katherine|     Buck|Female|conniecowan@examp...|+1-773-151-6685x4...|   1989-01-22|Intelligence analyst|\n",
      "|    8|2EFC6A4e77FaEaC|   Ricardo|   Hinton|  Male|wyattbishop@examp...|001-447-699-7998x...|   1924-03-26|      Hydrogeologist|\n",
      "|    9|baDcC4DeefD8dEB|      Dave|  Farrell|  Male| nmccann@example.net|  603-428-2429x27392|   2018-10-06|              Lawyer|\n",
      "|   10|8e4FB470FE19bF0|    Isaiah|    Downs|  Male|virginiaterrell@e...|+1-511-372-1544x8206|   1964-09-20|      Engineer, site|\n",
      "|   11|BF0BbA03C29Bb3b|    Sheila|     Ross|Female|huangcathy@exampl...|        895.881.4746|   2008-03-20|Advertising accou...|\n",
      "|   12|F738c69fB34E62E|     Stacy|   Newton|  Male|rayleroy@example.org|  710.673.3213x80335|   1980-10-20|       Warden/ranger|\n",
      "|   13|C03fDADdAadAdCe|     Mandy|    Blake|  Male|jefferynoble@exam...|  (992)466-1305x4947|   2007-12-08|Scientist, clinic...|\n",
      "|   14|b759b74BD1dE80d|   Bridget|     Nash|Female|mercedes44@exampl...|       (216)627-8359|   2004-06-28|       Social worker|\n",
      "|   15|1F0B7D65A00DAF9|   Crystal|   Farmer|  Male|pmiranda@example.org|     +1-024-377-5391|   1992-03-09|Agricultural cons...|\n",
      "|   16|50Bb061cB30B461|    Thomas|   Knight|Female|braunpriscilla@ex...|     +1-360-880-0766|   2006-02-18|Sport and exercis...|\n",
      "|   17|D6dbA5308fEC4BC|   Maurice|   Rangel|  Male|sheenabanks@examp...|       (246)187-4969|   2004-08-20|Secretary/adminis...|\n",
      "|   18|311D775990f066d|     Frank|  Meadows|  Male| gbrewer@example.org|   429.965.3902x4447|   2008-09-16|Audiological scie...|\n",
      "|   19|7F7E1BAcb0C9AFf|     Alvin|     Paul|  Male|gilbertdonaldson@...|  219.436.0887x07551|   1949-05-12|Teacher, adult ed...|\n",
      "|   20|88473e15D5c3cD0|     Jared| Mitchell|Female| jcortez@example.com|     +1-958-849-6781|   1921-01-18|    Paediatric nurse|\n",
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema= StructType().add(field=\"Index\",data_type=IntegerType())\\\n",
    "                    .add(field=\"User Id\",data_type=StringType())\\\n",
    "                    .add(field=\"First Name\",data_type=StringType())\\\n",
    "                    .add(field=\"Last Name\",data_type=StringType())\\\n",
    "                    .add(field=\"Sex\",data_type=StringType())\\\n",
    "                    .add(field=\"Email\",data_type=StringType())\\\n",
    "                    .add(field=\"Phone\",data_type=StringType())\\\n",
    "                    .add(field=\"Date of birth\",data_type=DateType())\\\n",
    "                    .add(field=\"Job Title\",data_type=StringType())\n",
    "\n",
    "\n",
    "df2=spark.read.csv(path='people-100.csv',schema=schema,header=True)\n",
    "display(df2)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "caf17dd4-4e36-4b49-9639-36c6b8723850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: bigint, city: string, email: string, food: array<string>, id: bigint, name: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-------------------+--------------------+---+-------+\n",
      "|age|        city|              email|                food| id|   name|\n",
      "+---+------------+-------------------+--------------------+---+-------+\n",
      "| 30| Los Angeles|  alice@example.com|     [apple, banana]|  1|  Alice|\n",
      "| 28|    New York|    bob@example.com|[orange, strawberry]|  2|    Bob|\n",
      "| 32|     Chicago|charlie@example.com|  [grape, blueberry]|  3|Charlie|\n",
      "| 29|     Houston|  david@example.com|   [pineapple, kiwi]|  4|  David|\n",
      "| 27|     Phoenix|    eve@example.com|      [mango, peach]|  5|    Eve|\n",
      "| 31|Philadelphia|  frank@example.com|  [pear, watermelon]|  6|  Frank|\n",
      "| 26| San Antonio|  grace@example.com|     [apple, cherry]|  7|  Grace|\n",
      "| 34|   San Diego|  henry@example.com|[banana, grapefruit]|  8|  Henry|\n",
      "| 25|      Dallas| isabel@example.com| [pineapple, papaya]|  9| Isabel|\n",
      "| 33|    San Jose|   jack@example.com|      [orange, plum]| 10|   Jack|\n",
      "+---+------------+-------------------+--------------------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#JSON files\n",
    "# in json we use multiline, if multiline json is there, By default its False\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Define the schema for the new DataFrame\n",
    "schema2 = StructType().add(\"Id\", LongType()).add(\"Name\", StringType()).add(\"Age\", IntegerType()).add(\"Email\", StringType()).add(\"City\", StringType()).add(\"Food\", ArrayType(StringType()))\n",
    "df_json=spark.read.json(path='people.json',multiLine=True)\n",
    "display(df_json)\n",
    "df_json.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1e32f3d-c3ca-4991-9e1f-ba3688c6b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark saves df data in chunks, not in a single file\n",
    "# mode can we ignore , error , append , overwrite\n",
    "df_json.write.json(\"save_json.json\",mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e35f8c02-9758-47cf-942a-558b5b5490a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-------------------+--------------------+---+-------+\n",
      "|age|        city|              email|                food| id|   name|\n",
      "+---+------------+-------------------+--------------------+---+-------+\n",
      "| 30| Los Angeles|  alice@example.com|     [apple, banana]|  1|  Alice|\n",
      "| 28|    New York|    bob@example.com|[orange, strawberry]|  2|    Bob|\n",
      "| 32|     Chicago|charlie@example.com|  [grape, blueberry]|  3|Charlie|\n",
      "| 29|     Houston|  david@example.com|   [pineapple, kiwi]|  4|  David|\n",
      "| 27|     Phoenix|    eve@example.com|      [mango, peach]|  5|    Eve|\n",
      "| 31|Philadelphia|  frank@example.com|  [pear, watermelon]|  6|  Frank|\n",
      "| 26| San Antonio|  grace@example.com|     [apple, cherry]|  7|  Grace|\n",
      "| 34|   San Diego|  henry@example.com|[banana, grapefruit]|  8|  Henry|\n",
      "| 25|      Dallas| isabel@example.com| [pineapple, papaya]|  9| Isabel|\n",
      "| 33|    San Jose|   jack@example.com|      [orange, plum]| 10|   Jack|\n",
      "+---+------------+-------------------+--------------------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new_json=spark.read.json(\"save_json.json\")\n",
    "df_new_json.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7d159b4-ef95-4016-a158-66aa395561b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df=spark.read.csv(path='people-100.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6940a55-d2f8-40a2-b009-55d753a4703b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+---------+------+---------------------+----------------------+-------------+---------------+\n",
      "|Index|User Id        |First Name|Last Name|Sex   |Email                |Phone                 |Date of birth|Job Title      |\n",
      "+-----+---------------+----------+---------+------+---------------------+----------------------+-------------+---------------+\n",
      "|1    |88F7B33d2bcf9f5|Shelby    |Terrell  |Male  |elijah57@example.net |001-084-906-7849x73518|1945-10-26   |Games developer|\n",
      "|2    |f90cD3E76f1A9b9|Phillip   |Summers  |Female|bethany14@example.com|214.112.6044x4913     |1910-03-24   |Phytotherapist |\n",
      "|3    |DbeAb8CcdfeFC2c|Kristine  |Travis   |Male  |bthompson@example.com|277.609.7938          |1992-07-02   |Homeopath      |\n",
      "+-----+---------------+----------+---------+------+---------------------+----------------------+-------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show function\n",
    "# default 20 rows and letter in columns\n",
    "\n",
    "csv_df.show(3, truncate=False)\n",
    "# csv_df.show(5, truncate=5,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5f8c0a85-65e8-4b96-aff3-f43bbf67bef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Index: string (nullable = true)\n",
      " |-- User Id: string (nullable = true)\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Last Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Phone: string (nullable = true)\n",
      " |-- Date of birth: string (nullable = true)\n",
      " |-- Job Title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "470ffc47-538a-4792-bd6b-174d419f4343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+---------------+\n",
      "|Index|        User Id|First Name|Last Name|   Sex|               Email|               Phone|Date of birth|      Job Title|\n",
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+---------------+\n",
      "|    1|88F7B33d2bcf9f5|    Shelby|  Terrell|  Male|elijah57@example.net|001-084-906-7849x...|   1945-10-26|Games developer|\n",
      "|    2|f90cD3E76f1A9b9|   Phillip|  Summers|Female|bethany14@example...|   214.112.6044x4913|   1910-03-24| Phytotherapist|\n",
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- Index: integer (nullable = true)\n",
      " |-- User Id: string (nullable = true)\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Last Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Phone: string (nullable = true)\n",
      " |-- Date of birth: string (nullable = true)\n",
      " |-- Job Title: string (nullable = true)\n",
      "\n",
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+---------------+\n",
      "|Index|        User Id|First Name|Last Name|   Sex|               Email|               Phone|Date of birth|      Job Title|\n",
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+---------------+\n",
      "|    5|88F7B33d2bcf9f5|    Shelby|  Terrell|  Male|elijah57@example.net|001-084-906-7849x...|   1945-10-26|Games developer|\n",
      "|   10|f90cD3E76f1A9b9|   Phillip|  Summers|Female|bethany14@example...|   214.112.6044x4913|   1910-03-24| Phytotherapist|\n",
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+---------------+-------+\n",
      "|Index|        User Id|First Name|Last Name|   Sex|               Email|               Phone|Date of birth|      Job Title|country|\n",
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+---------------+-------+\n",
      "|    5|88F7B33d2bcf9f5|    Shelby|  Terrell|  Male|elijah57@example.net|001-084-906-7849x...|   1945-10-26|Games developer|  India|\n",
      "|   10|f90cD3E76f1A9b9|   Phillip|  Summers|Female|bethany14@example...|   214.112.6044x4913|   1910-03-24| Phytotherapist|  India|\n",
      "+-----+---------------+----------+---------+------+--------------------+--------------------+-------------+---------------+-------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- Index: integer (nullable = true)\n",
      " |-- User Id: string (nullable = true)\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Last Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Phone: string (nullable = true)\n",
      " |-- Date of birth: string (nullable = true)\n",
      " |-- Job Title: string (nullable = true)\n",
      " |-- country: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# under standing withColumn\n",
    "from pyspark.sql.functions import col,lit\n",
    "df1=csv_df.withColumn(colName='Index',col=col('Index').cast('Integer'))\n",
    "df1.show(2)\n",
    "df1.printSchema()\n",
    "df2=df1.withColumn(colName='Index',col=col(\"index\")*5)\n",
    "df2.show(2)\n",
    "# creating new column\n",
    "df3=df2.withColumn(colName=\"country\",col=lit(\"India\"))\n",
    "df3.show(2)\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b767f9dd-ce6d-4d12-9fd1-fb2d73b1d0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+----------+---------+------+--------------------+--------------------+-------------+---------------+\n",
      "|my_index|        User Id|First Name|Last Name|   Sex|               Email|               Phone|Date of birth|      Job Title|\n",
      "+--------+---------------+----------+---------+------+--------------------+--------------------+-------------+---------------+\n",
      "|       1|88F7B33d2bcf9f5|    Shelby|  Terrell|  Male|elijah57@example.net|001-084-906-7849x...|   1945-10-26|Games developer|\n",
      "|       2|f90cD3E76f1A9b9|   Phillip|  Summers|Female|bethany14@example...|   214.112.6044x4913|   1910-03-24| Phytotherapist|\n",
      "+--------+---------------+----------+---------+------+--------------------+--------------------+-------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# withcolumRenamed\n",
    "csv_df.withColumnRenamed('Index',\"my_index\").show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3b80b42c-be69-4af4-ad3c-bff45521e503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+\n",
      "| id|           name|\n",
      "+---+---------------+\n",
      "|  1|{Nishant, ketu}|\n",
      "|  2|  {ajay, anand}|\n",
      "+---+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# struct type and struct field\n",
    "from pyspark.sql.types import *\n",
    "data=[(1,(\"Nishant\",\"ketu\")),(2,(\"ajay\",\"anand\"))]\n",
    "structName=StructType([StructField(name=\"first_name\",dataType=StringType()),StructField(name=\"last_name\",dataType=StringType())])\n",
    "schema=StructType([StructField(name='id',dataType=IntegerType()),StructField(name='name',dataType=structName)])\n",
    "df1=spark.createDataFrame(data,schema=schema)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ff2d7e96-95e4-4a0b-9a7e-3f570b33fc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------+\n",
      "|   name|         my-num|firstnum|\n",
      "+-------+---------------+--------+\n",
      "|nishant|[1, 2, 3, 4, 5]|       1|\n",
      "|   ketu|   [1, 4, 3, 4]|       1|\n",
      "+-------+---------------+--------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- my-num: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- firstnum: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Array type\n",
    "from pyspark.sql.types import *\n",
    "data=[(\"nishant\",[1,2,3,4,5]),(\"ketu\",[1,4,3,4])]\n",
    "schema=StructType([StructField(\"name\",StringType()),StructField(\"my-num\",ArrayType(IntegerType()))])\n",
    "df1=spark.createDataFrame(data,schema)\n",
    "df1=df1.withColumn(\"firstnum\",col('my-num')[0])\n",
    "df1.show()\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5a0f75d8-3f54-4544-9bb2-b9cd87f84bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------+------+\n",
      "|   name|         my-num|firstnum| merge|\n",
      "+-------+---------------+--------+------+\n",
      "|nishant|[1, 2, 3, 4, 5]|       1|[1, 1]|\n",
      "|   ketu|   [1, 4, 3, 4]|       1|[1, 1]|\n",
      "+-------+---------------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array\n",
    "df2=df1.withColumn(\"merge\",array(df1.firstnum,df1.firstnum))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c247bb-1aea-43dd-b136-2bc626199cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
